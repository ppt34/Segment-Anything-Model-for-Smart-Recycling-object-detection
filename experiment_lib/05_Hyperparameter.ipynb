{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffd4388-ea66-4c4c-8a23-1404d960d2b0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4767053c-4008-4341-b0a9-7186e0142971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch_lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ecc21-c829-4bb6-9560-9920dabe0df1",
   "metadata": {},
   "source": [
    "## Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7377d68-3941-4f31-8a21-79af57f1f4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO add a way to pass reduction as optional param\n",
    "def get_criterion(god):\n",
    "    \n",
    "    def get_criterion_kwargs():\n",
    "        criterion_config = god.config['hp']['criterion']\n",
    "        reduction = criterion_config['reduction'] if 'reduction' in criterion_config else 'mean'\n",
    "        return {'reduction': reduction}\n",
    "        # !!! weight kwarg is WIP !!!\n",
    "        # if 'weight' in criterion_config:\n",
    "        #     if criterion_config['weight'] == 'autobalanced':\n",
    "        #         auto_weight = 1 - (tensor(config['train_class_counts']) / tensor(config['train_class_counts']).sum())\n",
    "        #         kwargs['weight'] = auto_weight.to(device if not force_cpu else 'cpu')\n",
    "        #     else:\n",
    "        #         kwargs['weight'] = criterion_config['weight'].to(device if not force_cpu else 'cpu')\n",
    "    \n",
    "    criterion_name = god.config['hp']['criterion']['name']\n",
    "    criterion_kwargs = get_criterion_kwargs()\n",
    "    clf_type = god.config['model']['classification_type']\n",
    "    \n",
    "    if criterion_name == 'L1Loss' and clf_type == 'binary':\n",
    "        criterion = nn.L1Loss(**criterion_kwargs)\n",
    "        return lambda pred,inp: criterion(pred.squeeze(-1), inp.float())\n",
    "    \n",
    "    elif criterion_name == 'MSELoss' and clf_type == 'binary':\n",
    "        criterion = nn.MSELoss(**criterion_kwargs)\n",
    "        return lambda pred,inp: criterion(pred.squeeze(-1), inp.float())\n",
    "    \n",
    "    elif criterion_name == 'BCELoss' and clf_type == 'binary':\n",
    "        criterion = nn.BCELoss(**criterion_kwargs)\n",
    "        return lambda pred,inp: criterion(pred.squeeze(-1), inp.float())\n",
    "        \n",
    "    elif criterion_name == 'BCEWithLogitsLoss' and clf_type == 'custom':\n",
    "        criterion = nn.BCEWithLogitsLoss(**criterion_kwargs)\n",
    "        return lambda pred,inp: criterion(pred.squeeze(-1), inp.float())\n",
    "    \n",
    "    elif criterion_name == 'CrossEntropyLoss' and clf_type == 'multiclass':\n",
    "        return nn.CrossEntropyLoss(**criterion_kwargs)\n",
    "        \n",
    "    elif criterion_name == 'HierarchicalLoss' and clf_type == 'fish_hierarchical':\n",
    "        return HierarchicalLoss(**criterion_kwargs)\n",
    "    \n",
    "    elif criterion_name == 'L1Loss' and clf_type == 'multiclass_sigmoid':\n",
    "        criterion = nn.L1Loss(**criterion_kwargs)\n",
    "        return lambda pred,inp: criterion(pred,  F.one_hot(inp, num_classes=8)) # TODO determine num_classes from config\n",
    "    \n",
    "    elif criterion_name == 'BCELoss' and clf_type == 'multiclass_sigmoid':\n",
    "        criterion = nn.BCELoss(**criterion_kwargs)\n",
    "        return lambda pred,inp: criterion(pred, F.one_hot(inp, num_classes=8).float()) # TODO determine num_classes from config\n",
    "    \n",
    "    elif criterion_name == 'BCELoss' and clf_type == 'multiclass_threshold':\n",
    "        criterion = nn.BCELoss(**criterion_kwargs)\n",
    "        return lambda pred,inp: criterion(pred, ((inp-1).unsqueeze(-1) == torch.arange(7, device=pred.device)).float()) # TODO determine num_classes (-1) from config\n",
    "\n",
    "    elif criterion_name == 'SoftF1Loss' and clf_type == 'multiclass':\n",
    "        return SoftF1Loss(**criterion_kwargs)\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f\"get_criterion has no implementation for config with criterion '{criterion_name}' and classification_type '{clf_type}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebb5714-029d-48fd-b727-dc98ceb04cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_optimizer(god, custom_lr=None):\n",
    "    optim_name = god.config['hp']['optimizer']['name']\n",
    "    if optim_name == 'SGD':\n",
    "        optim_class = optim.SGD\n",
    "    elif optim_name == 'Adam':\n",
    "        optim_class = optim.Adam\n",
    "    else:\n",
    "        raise Exception(f\"Optimizer with name '{optim_name}' current not supported.\")\n",
    "        \n",
    "    return optim_class([p for p in god.model.parameters() if p.requires_grad], lr=custom_lr or god.config['hp']['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03bd7249-fcfe-41b0-aea1-46117e8c095a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_scheduler(god):\n",
    "    sched_config = god.config['hp']['scheduler']\n",
    "    if sched_config == 'None':\n",
    "        return None\n",
    "    if sched_config['name'] == 'OneCycleLr':\n",
    "        return lr_scheduler.OneCycleLR(\n",
    "               god.optimizer, \n",
    "               max_lr = sched_config['max_lr'],\n",
    "               steps_per_epoch = len(god.dataloaders['train']),\n",
    "               epochs = god.config['training']['n_epochs'],\n",
    "               anneal_strategy = sched_config['anneal_strategy'])\n",
    "        \n",
    "    raise Exception(f\"Scheduler with name '{sched_config['name']}' is not supported yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7224eabd-8b0d-47e1-8c72-a32783e8350f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def run_lr_finder(god):\n",
    "    lr_finder = LRFinder(god.model, god.optimizer, god.criterion, device='cuda')\n",
    "    lr_finder.range_test(god.dataloaders['train'], end_lr=100, num_iter=100)\n",
    "    lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "    lr_finder.reset() # to reset the model and optimizer to their initial state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2efdcaf-a5e2-4d57-9e2f-12057b7c2801",
   "metadata": {},
   "source": [
    "## Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b04983e-213d-4584-9474-85880d6200fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class HierarchicalLoss(nn.Module):\n",
    "    def __init__(self, reduction=None, weight=None):\n",
    "        if weight is not None:\n",
    "            raise Exception('Weight parameter currently not supported by HierarchicalLoss')\n",
    "        \n",
    "        super(HierarchicalLoss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction=reduction)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        fish_not_fish_output, fish_type_output = outputs\n",
    "\n",
    "        # Create \"fish or not fish\" labels based on the fish type labels\n",
    "        fish_not_fish_target = (targets > 0).long()\n",
    "\n",
    "        fish_not_fish_loss = self.loss_fn(fish_not_fish_output, fish_not_fish_target)\n",
    "\n",
    "        # Only consider the fish type loss for the samples that are actually fish\n",
    "        fish_mask = fish_not_fish_target == 1\n",
    "        if fish_mask.sum() > 0:\n",
    "            fish_type_loss = self.loss_fn(fish_type_output[fish_mask], targets[fish_mask] - 1)  # -1 to shift the fish type labels to start from 0\n",
    "        else:\n",
    "            fish_type_loss = 0\n",
    "\n",
    "        return fish_not_fish_loss + fish_type_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c40051c-1f4f-4aeb-a118-0f2c5d881874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class SoftF1Loss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7, reduction=None, weight=None):\n",
    "        super(SoftF1Loss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        # Sigmoid activation to get probabilities\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        # Soft versions of precision and recall\n",
    "        tp = torch.sum(labels * probs, dim=0)\n",
    "        fp = torch.sum((1 - labels) * probs, dim=0)\n",
    "        fn = torch.sum(labels * (1 - probs), dim=0)\n",
    "\n",
    "        soft_precision = tp / (tp + fp + self.epsilon)\n",
    "        soft_recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        # Soft F1 score\n",
    "        soft_f1 = 2 * (soft_precision * soft_recall) / (soft_precision + soft_recall + self.epsilon)\n",
    "        # Since we want to minimize the loss, we return 1 - soft_f1\n",
    "        return 1 - torch.mean(soft_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a1760-e795-4473-8190-3fcd6dc84e98",
   "metadata": {},
   "source": [
    "## Test+Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae702f5f-afd0-401d-b5bf-b254d31fe53f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 04_Hyperparameter.ipynb to exp/Hyperparameter.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 04_Hyperparameter.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
