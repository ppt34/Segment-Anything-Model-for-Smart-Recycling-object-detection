{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b45e96-dfb4-42e9-a34e-40c000da240e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f0e770-8ec6-4bdd-a6e9-98d5c1c51a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from tqdm.notebook import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1b54d-5e18-46df-ae9a-e857c6743828",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45bede6b-9d45-4866-afcd-6d353b2603df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_device(god):\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print('Warning: No cuda device found.')\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca088655-da9a-4500-bb8c-e7f82418b4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def one_episode(god):\n",
    "    god.before_episode()\n",
    "    \n",
    "    n_epochs = god.config['training']['n_epochs']\n",
    "    use_progress_bar = god.config['training']['output']['progress_bar']['epoch']\n",
    "    for epoch in tqdm(range(1, n_epochs+1)) if use_progress_bar else range(1, n_epochs+1):\n",
    "        one_epoch(god)        \n",
    "        \n",
    "    god.after_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac8be45-f00b-4777-bead-9fbe02056305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def one_epoch(god):\n",
    "    god.before_epoch()\n",
    "    \n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "            god.model.train()\n",
    "        elif (god.state['epoch_nr'] % god.config['training'].get('val_frequency', 1)) == 0:\n",
    "            god.model.eval()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        god.before_phase(phase)\n",
    "        \n",
    "        use_progress_bar = god.config['training']['output']['progress_bar']['batch']\n",
    "        for xb, yb in tqdm(god.dataloaders[phase]) if use_progress_bar else god.dataloaders[phase]:\n",
    "            one_batch(god, xb, yb)\n",
    "        \n",
    "        god.after_phase()\n",
    "                \n",
    "    god.after_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0766c89b-cdbf-4448-aa8a-6e783376d1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07b5fa0-8362-42be-92d5-f0c4edf5d7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def one_batch(god, xb, yb):\n",
    "    god.before_batch(xb, yb)\n",
    "    \n",
    "    xb, yb = xb.to(god.device), yb.to(god.device)\n",
    "    with torch.set_grad_enabled(god.state['phase'] == 'train'):\n",
    "        pred = god.model(xb)\n",
    "        loss = god.criterion(pred, yb)\n",
    "        if god.state['phase'] == 'train':\n",
    "            god.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            god.optimizer.step()\n",
    "            if god.scheduler: god.scheduler.step()\n",
    "    \n",
    "    # todo work around for tuple pred, this likely should just use some class that supports a custom detach method instead of tuple\n",
    "    god.after_batch(pred.detach().cpu() if type(pred) != tuple else [p.detach().cpu() for p in pred], loss.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "079e9109-38fd-4dd8-b1db-7f9096b98d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTDATED AND NOT USED\n",
    "def train_model(config, model, criterion, optimizer, dataloaders, n_epochs=25, scheduler=None, silent=False, advanced_metrics=False):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch, best_acc, best_train_acc = 1, 0., 0.\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "    train_precision, train_recall, val_precision, val_recall = [], [], [], []  # added precision and recall lists\n",
    "    train_f1, val_f1 = [], []  # added F1 score lists\n",
    "\n",
    "    for epoch in tqdm(range(0, n_epochs+1)) if not silent else range(0, n_epochs+1):\n",
    "        if not silent: print('-' * 10)\n",
    "        if not silent: print(f'Epoch {epoch}/{n_epochs}')\n",
    "        \n",
    "        for phase in ('train', 'val'):\n",
    "            if god.state['phase'] == 'train':\n",
    "                if epoch == 0: continue\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "        \n",
    "            n = 0\n",
    "            running_loss = 0.0\n",
    "            running_corrects  = 0\n",
    "\n",
    "            # Initiate lists for precision, recall and f1_score calculation\n",
    "            true_labels = []\n",
    "            pred_labels = []\n",
    "\n",
    "            for xb, yb in dataloaders[phase]:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(god.state['phase'] == 'train'):\n",
    "                    pred = model(xb)\n",
    "                    loss = criterion(pred, yb)\n",
    "                    if god.state['phase'] == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if scheduler: scheduler.step()\n",
    "\n",
    "                n += xb.size(0)\n",
    "                running_loss += loss.item() * xb.size(0)\n",
    "                running_corrects += (get_pred_class(config, pred) == yb).int().sum().item()\n",
    "\n",
    "                # Add the true and predicted labels for this batch to the lists\n",
    "                true_labels.extend(yb.cpu().numpy())\n",
    "                pred_labels.extend(get_pred_class(config, pred).cpu().numpy())\n",
    "                \n",
    "\n",
    "            epoch_loss = running_loss / n\n",
    "            epoch_acc = running_corrects / n\n",
    "\n",
    "            if advanced_metrics:\n",
    "                labels_to_consider = [i for i in range(1, len(config['id2label']))]\n",
    "                epoch_precision = precision_score(true_labels, pred_labels, labels=labels_to_consider, average='macro') \n",
    "                epoch_recall = recall_score(true_labels, pred_labels, labels=labels_to_consider, average='macro')\n",
    "                epoch_f1 = f1_score(true_labels, pred_labels, labels=labels_to_consider, average='macro')\n",
    "            #if advanced_metrics: epoch_precision = precision_score(true_labels, pred_labels, average='macro') # pos_label=1, \n",
    "            #if advanced_metrics: epoch_recall = recall_score(true_labels, pred_labels, average='macro')\n",
    "            #if advanced_metrics: epoch_f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "            if not silent and advanced_metrics: print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Precision: {epoch_precision:.4f} Recall: {epoch_recall:.4f} F1-score: {epoch_f1:.4f}')\n",
    "            elif not silent: print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'train': \n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "                if advanced_metrics: train_precision.append(epoch_precision)\n",
    "                if advanced_metrics: train_recall.append(epoch_recall)\n",
    "                if advanced_metrics: train_f1.append(epoch_f1)\n",
    "                best_train_acc = max(epoch_acc, best_train_acc)\n",
    "                \n",
    "            if phase == 'val':\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_acc.append(epoch_acc)\n",
    "                if advanced_metrics: val_precision.append(epoch_precision)\n",
    "                if advanced_metrics: val_recall.append(epoch_recall)\n",
    "                if advanced_metrics: val_f1.append(epoch_f1)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    best_epoch = epoch\n",
    "                \n",
    "        if not silent: print()\n",
    "    \n",
    "    \n",
    "    save_results(config, model, train_loss, train_acc, val_loss, val_acc, best_model_wts, best_acc, best_train_acc, best_epoch, n_epochs)\n",
    "    return model, train_acc, val_acc, train_precision, train_recall, train_f1, val_precision, val_recall, val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d043044-5e5d-48b7-9da5-2b17072b4492",
   "metadata": {},
   "source": [
    "## Training util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a2159ff-87bd-42d0-ae6d-abe891d525c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP\n",
    "def old_save_results(config, model, train_loss, train_acc, val_loss, val_acc, best_model_wts, best_acc, best_train_acc, best_epoch, n_epochs):\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    history_json = os.path.join(base_path, config['history_json'])\n",
    "    \n",
    "    if not os.path.isfile(history_json):\n",
    "        with open(history_json, 'w') as f:\n",
    "            json.dump({'history': []}, f)\n",
    "    \n",
    "    with open(history_json, 'r+') as f:\n",
    "        metrics = {'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc}\n",
    "        result = {\n",
    "            'name': model.name,\n",
    "            'date': datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "            'best_val_acc': best_acc,\n",
    "            'best_val_acc_epoch': f'{best_epoch}/{n_epochs}',\n",
    "            'best_train_acc': best_train_acc,\n",
    "            'metrics': metrics,\n",
    "            'hp': config['hp'].__str__()\n",
    "        }\n",
    "        root = json.load(f)\n",
    "        root['history'].append(result)\n",
    "        f.seek(0)\n",
    "        json.dump(root, f)    \n",
    "        f.truncate()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4645e06c-58ca-44de-ba87-ac870de43fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP\n",
    "def save_model(config, model, name):\n",
    "    output_dir = os.path.join('weights', name)\n",
    "    os.makedirs(output_dir)\n",
    "    torch.save(model, os.path.join(output_dir, f'{name}.pth'))\n",
    "    torch.save(model, os.path.join(output_dir, f'params_{name}.pth'))\n",
    "    torch.save(config, os.path.join(output_dir, f'config_{name}.pth'))\n",
    "    with open(os.path.join(output_dir, f'config_raw_{name}.txt'), 'w') as f: f.write(str(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a05dd3-62f8-4c2c-934f-b148c6211683",
   "metadata": {},
   "source": [
    "## Test+Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d495c5d1-3c8f-4a80-a28d-ff5ab24b5a12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 05_Training.ipynb to exp/Training.py\n"
     ]
    }
   ],
   "source": [
    "!python _notebook2script.py 05_Training.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
