{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8d8b7e-8fbd-4a95-92e3-9f71e8cf08da",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2da9f33-3664-4f1a-bee5-dfa55c899995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import tensor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33521a69-5e2f-411e-8272-2608d4123a8a",
   "metadata": {},
   "source": [
    "## Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc2bd32-7358-4ba3-bd0f-3eddd45b1967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_datasets(god):\n",
    "    if not os.path.isdir(god.config['dataset']['path']):\n",
    "        raise Exception(f\"Dataset at path '{god.config['dataset']['path']}' was not found, make sure that the provided path in config.dataset.path is correct.\")\n",
    "    \n",
    "    ds_type = god.config['dataset']['type']\n",
    "    if ds_type == 'ImageDir':\n",
    "        return get_ImageDirDataset(god)\n",
    "    if ds_type == 'ImageDirInMemory':\n",
    "        return get_ImageDirInMemoryDataset(god)\n",
    "    elif ds_type == 'IdxImageDir':\n",
    "        return get_IdxImageDirDataset(god)\n",
    "    if ds_type == 'ImageFileName':\n",
    "        return get_ImageFileNameDataset(god)\n",
    "    raise Exception(f\"dataset type '{ds_type}' not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772ce97d-6fba-49ea-a17f-483bd48b74aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dataloaders(god):\n",
    "    return {\n",
    "        'train': DataLoader(god.datasets['train'], batch_size=god.config['hp']['batch_size'], num_workers=get_num_workers(god), sampler=god.samplers['train']),\n",
    "        'val': DataLoader(god.datasets['val'], batch_size=god.config['hp']['batch_size'], num_workers=get_num_workers(god), sampler=god.samplers['val'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06cc72ce-c277-45f2-a2a6-bcf3aa073a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export \n",
    "def get_num_workers(god):\n",
    "    if 'num_workers' in god.config['constants']:\n",
    "        return god.config['constants']['num_workers']\n",
    "    if os.cpu_count() > 0:\n",
    "        return os.cpu_counts()\n",
    "    else:\n",
    "        warnings.warn('Could not determine number of cores via os.cpu_count(), using 4 as default')\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2130e62-df7c-4ffd-b170-0f94249785ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data_transforms(god):\n",
    "    data_transforms = {}\n",
    "    for phase in ('train', 'val'):\n",
    "        phase_transforms = [get_data_transform(god, t) for t in god.config['data_transforms'][phase]]\n",
    "        data_transforms[phase] = transforms.Compose([t for t in phase_transforms if t is not None])\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d96aa6-ad98-4143-b4df-af231b40cf52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_mean_std_per_channel(god):\n",
    "    n, total_sum, total_square_sum = 0, tensor([0.,0.,0.]), tensor([0.,0.,0.])\n",
    "    for xb, yb in god.dataloaders['train']:\n",
    "        n += xb.numel() // xb.shape[1]  # Number of samples, excluding channel dimension\n",
    "        total_sum += xb.sum(dim=(0,2,3))\n",
    "        total_square_sum += (xb**2).sum(dim=(0,2,3))\n",
    "\n",
    "    mean = total_sum / n\n",
    "    std_dev = torch.sqrt((total_square_sum / n) - mean**2)\n",
    "    return mean.tolist(), std_dev.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f63e27-77be-4004-b1ca-a71be85e9de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_class_counts(god):\n",
    "    class_counts = {}\n",
    "    for phase in ('train', 'val'):\n",
    "        dl = god.dataloaders[phase]\n",
    "        indices = list(dl.sampler)\n",
    "        targets = torch.tensor([dl.dataset.get_y(i) for i in indices])\n",
    "        class_counts[phase] = targets.bincount().int().tolist()\n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be7d979-53ed-487c-a4dd-c4ebf3ed4595",
   "metadata": {},
   "source": [
    "## Get Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a604ad58-d6f9-4df9-a479-c25b2f35692a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO combine the similar approaches and just change the dataset class\n",
    "\n",
    "\n",
    "def get_ImageDirDataset(god):\n",
    "    return {\n",
    "        'train': ImageDirDataset.from_directory(\n",
    "            os.path.join(god.config['dataset']['path'], god.config['dataset']['train_path']),\n",
    "            god.config['label2id'],\n",
    "            transform=god.data_transforms['train']\n",
    "        ),\n",
    "        'val':  ImageDirDataset.from_directory(\n",
    "            os.path.join(god.config['dataset']['path'], god.config['dataset']['val_path']),\n",
    "            god.config['label2id'],\n",
    "            transform=god.data_transforms['val']\n",
    "        )\n",
    "    }\n",
    "\n",
    "def get_ImageDirInMemoryDataset(god):\n",
    "    return {\n",
    "        'train': ImageDirInMemoryDataset(\n",
    "            os.path.join(god.config['dataset']['path'], god.config['dataset']['train_path']),\n",
    "            god.config['label2id'],\n",
    "            transform=god.data_transforms['train']\n",
    "        ),\n",
    "        'val':  ImageDirInMemoryDataset(\n",
    "            os.path.join(god.config['dataset']['path'], god.config['dataset']['val_path']),\n",
    "            god.config['label2id'],\n",
    "            transform=god.data_transforms['val']\n",
    "        )\n",
    "    }\n",
    "\n",
    "def get_IdxImageDirDataset(god):\n",
    "    img_dir_ds =  ImageDirDataset.from_directory(god.config['dataset']['path'], god.config['label2id'])\n",
    "\n",
    "    val_pct = god.config['dataset']['val_pct']\n",
    "    length = len(img_dir_ds)\n",
    "    val_size = int(val_pct * length)\n",
    "\n",
    "    perm = torch.randperm(length)\n",
    "    train_idxs = perm[val_size:]\n",
    "    val_idxs = perm[:val_size]\n",
    "    \n",
    "    return {\n",
    "        'train': IdxImageDirDataset(img_dir_ds, train_idxs, god.config['data_transforms']['train']),\n",
    "        'val':  IdxImageDirDataset(img_dir_ds, val_idxs, god.config['data_transforms']['val'])\n",
    "    }\n",
    "\n",
    "def get_ImageFileNameDataset(god):\n",
    "    return {\n",
    "        'train': ImageFileNameDataset.from_directory(\n",
    "            os.path.join(god.config['dataset']['path'], god.config['dataset']['train_path']),\n",
    "            god.config['dataset']['filename2label'],\n",
    "            god.config['label2id'],\n",
    "            god.data_transforms['train']\n",
    "        ),\n",
    "        'val': ImageFileNameDataset.from_directory(\n",
    "            os.path.join(god.config['dataset']['path'], god.config['dataset']['val_path']),\n",
    "            god.config['dataset']['filename2label'],\n",
    "            god.config['label2id'],\n",
    "            god.data_transforms['val']\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8ce5ab-a510-4e9b-ac3b-1404c39e21db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data_transform(god, transform_dict):\n",
    "    if transform_dict['name'] == 'SquarePad':\n",
    "        extra_pad = transform_dict['extra_pad'] if 'extra_pad' in transform_dict else 0\n",
    "        return SquarePad(extra_pad=extra_pad)\n",
    "    \n",
    "    elif transform_dict['name'] == 'Resize':\n",
    "        return transforms.Resize(transform_dict['size'])\n",
    "        \n",
    "    elif transform_dict['name'] == 'ToTensor':\n",
    "        return transforms.ToTensor()\n",
    "        \n",
    "    elif transform_dict['name'] == 'Grayscale':\n",
    "        num_output_channels = transform_dict['num_output_channels'] if 'num_output_channels' in transform_dict else 1\n",
    "        return transforms.Grayscale(num_output_channels=num_output_channels)\n",
    "    \n",
    "    elif transform_dict['name'] == 'Cutout':\n",
    "        return Cutout(transform_dict['n_holes'], transform_dict['length'])\n",
    "    \n",
    "    elif transform_dict['name'] == 'CenterCrop':\n",
    "        return transforms.CenterCrop(transform_dict['size'])\n",
    "    \n",
    "    # TODO add support for remaining settings\n",
    "    elif transform_dict['name'] == 'RandomCrop':\n",
    "        return transforms.RandomCrop(transform_dict['size'])\n",
    "    \n",
    "    elif transform_dict['name'] == 'RandomHorizontalFlip':\n",
    "        return transforms.RandomHorizontalFlip(transform_dict.get('p', 0.5))\n",
    "    \n",
    "    elif transform_dict['name'] == 'RandomVerticalFlip':\n",
    "        return transforms.RandomVerticalFlip(transform_dict.get('p', 0.5))\n",
    "    \n",
    "    # TODO add support for remaining settings\n",
    "    elif transform_dict['name'] == 'RandomRotation':\n",
    "        return transforms.RandomRotation(transform_dict['degrees'])\n",
    "    \n",
    "    # TODO add support for remaining settings\n",
    "    elif transform_dict['name'] == 'RandomResizedCrop':\n",
    "        return transforms.RandomResizedCrop(transform_dict['size'])\n",
    "        \n",
    "    elif transform_dict['name'] == 'Normalize':\n",
    "        if not 'x_mean' in god.config['constants'] or not 'x_std' in god.config['constants']:\n",
    "            warnings.warn('Normalize Transform will not be used since it needs config.constants.x_mean and config.constants.x_std to be set. They can be obtained by calling god.print_x_mean_and_std().')\n",
    "            return None\n",
    "            \n",
    "        return transforms.Normalize(god.config['constants']['x_mean'], god.config['constants']['x_std'])\n",
    "    \n",
    "    raise Exception(f\"Transform with name '{transform_dict['name']}' is not supported.\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6d9a2-6b53-4745-965b-b49d61c69f61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d40ab2f-750e-48c6-a531-392f5ab8f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageDirDataset():\n",
    "    @staticmethod\n",
    "    def from_directory(image_directory, label2id, transform=transforms.Compose([]), in_memory=False, image_extensions=['.png', '.jpg', '.jpeg']):\n",
    "            image_label_tuples = []\n",
    "            for label in os.listdir(image_directory):\n",
    "                if label.startswith('IGNORE_LABEL') or label.startswith('.') : continue\n",
    "                for image in os.listdir(os.path.join(image_directory, label)):\n",
    "                    if any(image.endswith(ext) for ext in image_extensions):\n",
    "                        image_label_tuples.append((image, label))\n",
    "                        \n",
    "            return ImageDirDataset(image_directory, image_label_tuples, label2id, transform)\n",
    "        \n",
    "    \n",
    "    def __init__(self, img_dir, image_label_tuples, label2id, transform=transforms.Compose([])):\n",
    "        self.img_dir, self.image_label_tuples, self.label2id, self.transform = img_dir, image_label_tuples, label2id, transform\n",
    "        self[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        img_name, img_label = self.image_label_tuples[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_label, img_name)\n",
    "        return self.transform(Image.open(img_path).convert('RGBA').convert('RGB')), self.label2id[img_label]\n",
    "    \n",
    "    \n",
    "    def get_y(self, idx):\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        return self.label2id[self.image_label_tuples[idx][1]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_label_tuples)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageDirInMemoryDataset():\n",
    "    def __init__(self, img_dir, label2id, transform=transforms.Compose([]), image_extensions=['.png', '.jpg', '.jpeg']):\n",
    "        self.img_dir = img_dir\n",
    "        self.label2id = label2id\n",
    "        self.transform = transform\n",
    "        self.image_extensions = image_extensions\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        self._load_images()\n",
    "\n",
    "    def _load_images(self):\n",
    "        for label in tqdm(os.listdir(self.img_dir)):\n",
    "            if label.startswith('IGNORE_LABEL') or label.startswith('.') : continue\n",
    "            for image in tqdm(os.listdir(os.path.join(self.img_dir, label))):\n",
    "                if any(image.endswith(ext) for ext in self.image_extensions):\n",
    "                    image_path = os.path.join(self.img_dir, label, image)\n",
    "                    image_tensor = self.transform(Image.open(image_path).convert('RGBA').convert('RGB'))\n",
    "                    self.images.append(image_tensor)\n",
    "                    self.labels.append(self.label2id[label])\n",
    "\n",
    "        # Convert lists of images and labels to tensors\n",
    "        #self.images = torch.stack(self.images)\n",
    "        #self.labels = torch.tensor(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bcf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageDirDataset():\n",
    "    @staticmethod\n",
    "    def from_directory(image_directory, label2id, transform=transforms.Compose([]), image_extensions=['.png', '.jpg', '.jpeg']):\n",
    "            image_label_tuples = []\n",
    "            for label in os.listdir(image_directory):\n",
    "                if label.startswith('IGNORE_LABEL') or label.startswith('.') : continue\n",
    "                for image in os.listdir(os.path.join(image_directory, label)):\n",
    "                    if any(image.endswith(ext) for ext in image_extensions):\n",
    "                        image_label_tuples.append((image, label))\n",
    "                        \n",
    "            return ImageDirDataset(image_directory, image_label_tuples, label2id, transform)\n",
    "        \n",
    "    \n",
    "    def __init__(self, img_dir, image_label_tuples, label2id, transform=transforms.Compose([])):\n",
    "        self.img_dir, self.image_label_tuples, self.label2id, self.transform = img_dir, image_label_tuples, label2id, transform\n",
    "        self[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        img_name, img_label = self.image_label_tuples[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_label, img_name)\n",
    "        return self.transform(Image.open(img_path).convert('RGBA').convert('RGB')), self.label2id[img_label]\n",
    "    \n",
    "    \n",
    "    def get_y(self, idx):\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        return self.label2id[self.image_label_tuples[idx][1]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_label_tuples)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e6fbd2-7fa5-4d26-bb77-714d0e420ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# wrapper for ImageDirDataset to support custom indices    \n",
    "class IdxImageDirDataset():\n",
    "    def __init__(self, image_dir_ds, idxs, transform=transforms.Compose([])):\n",
    "        self.ds, self.idxs, self.transform = image_dir_ds, idxs, transform\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        x,y = self.ds[self.idxs[idx].item()]\n",
    "        return self.transform(x), y\n",
    "    \n",
    "    def get_y(self, idx):\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        return self.ds.get_y(self.idxs[idx].items())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idxs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fe2073-d210-4538-8843-a0d0e003730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exprt\n",
    "class ImageFileNameDataset():\n",
    "    @staticmethod\n",
    "    def from_directory(image_directory, filename2label, label2id, transform=transforms.Compose([]), image_extensions=['.png', '.jpg', '.jpeg']):\n",
    "        image_label_tuples = []\n",
    "        for image_name in os.listdir(image_directory):\n",
    "            if not any(image_name.endswith(ext) for ext in image_extensions):\n",
    "                continue\n",
    "            image_file = os.path.join(image_directory, image_name)\n",
    "            image_label = filename2label(image_name)\n",
    "            image_label_tuples.append((image_name, image_label))\n",
    "            \n",
    "        return ImageFileNameDataset(image_directory, image_label_tuples, label2id, transform)\n",
    "        \n",
    "    def __init__(self, image_directory, image_label_tuples, label2id, transform=transforms.Compose([])):\n",
    "        self.image_directory, self.image_label_tuples, self.label2id, self.transform = image_directory, image_label_tuples, label2id, transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        img_name, img_label = self.image_label_tuples[idx]\n",
    "        img_path = os.path.join(self.image_directory, img_name)\n",
    "        return self.transform(Image.open(img_path).convert('RGBA').convert('RGB')), self.label2id[img_label]\n",
    "    \n",
    "    def get_y(self, idx):\n",
    "        if type(idx) != int: raise Exception(f'Only int index support for now, got idx of type \"{type(idx).__name__}\"')\n",
    "        return self.label2id[self.image_label_tuples[idx][1]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_label_tuples)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a736e1e6-e726-4560-b57d-79115634603b",
   "metadata": {},
   "source": [
    "## Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262384c0-eea6-4ce5-bc4a-3707e9d9eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SquarePad:\n",
    "    def __init__(self, extra_pad=0): self.extra_pad = extra_pad\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        s = image.size\n",
    "        max_wh = np.max([s[-1], s[-2]])\n",
    "        hp = int((max_wh - s[-2]) / 2) + self.extra_pad\n",
    "        vp = int((max_wh - s[-1]) / 2) + self.extra_pad\n",
    "        padding = (hp, vp)\n",
    "        return transforms.Pad(padding, 0, 'constant')(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "687d94df-8367-4dff-90b3-37c9ac493d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f578f-e2b3-48b5-8fb8-25861c4848e3",
   "metadata": {},
   "source": [
    "## Data Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a75854-d113-4e8e-916e-6f5c3e5d7e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OLD\n",
    "def calc_mean_std_per_channel(god):\n",
    "    n, total_mean, total_std = 0, tensor([0.,0.,0.]), tensor([0.,0.,0.])\n",
    "    for dl in god.dataloaders.values():\n",
    "        for xb,yb in dl:\n",
    "            n += len(xb)\n",
    "            total_mean.add_(xb.mean(dim=(0,2,3)) * len(xb))\n",
    "            total_std.add_(xb.std(dim=(0,2,3)) * len(xb))\n",
    "        \n",
    "    return (total_mean / n).tolist(), (total_std / n).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814a336-bb1f-41a1-b3ed-565dd1ed2b4b",
   "metadata": {},
   "source": [
    "## Test+Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e60ec-188d-4b15-889e-f480eeebfe94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python _notebook2script.py 02_Data.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
