{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca98aa2-c1c8-4fbe-93e2-a0b68719a44a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Turns bounding boxes into segmented images, using the sam model segment predictions. \n",
    "##### (Warning: Just a proof of concept. In order to be able to execute this notebook the open fishery dataset is required) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe9324-75a1-419d-b043-c1ec51a55fa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5c6811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, cv2, torch, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a459346-b91e-44cb-836f-708c9e65a995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_df(df, count_per_label=20):\n",
    "    # only include rows that are fish labels\n",
    "    df = df[df['label_l2'].isin(['YFT', 'ALB', 'OTH', 'BILL', 'DOL', 'BET', 'SKJ'])].copy()\n",
    "    df['img_cat'] = df['img_id'].str[:3].map({'94a': 'A', '94b': 'B', '94c': 'C', '94d': 'D', '94e': 'E', '94f': 'F'})\n",
    "\n",
    "    # Group by 'label_l2', sample rows from each group\n",
    "    df = df.groupby('label_l2').apply(\n",
    "        lambda x: x.sample(count_per_label, random_state=42)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875667a6-443f-475f-a232-b1e141995b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "weights_dir_path = os.path.join(base_path, 'weights')\n",
    "weights_path = os.path.join(weights_dir_path, 'sam_vit_h_4b8939.pth')\n",
    "\n",
    "raw_ds = 'fishnet_v100'\n",
    "data_path =  os.path.join(base_path, 'raw_data', raw_ds)\n",
    "image_data_path = data_path\n",
    "\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_path, '_annotations.csv'))\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(image_data_path, '_df_train.csv')) #process_df(df[df['train']].copy(), count_per_label=1000)\n",
    "bboxes_dict_train = {'bboxes': {f'{filename}.jpg': {vals['label_l2'].values[0]: [np.array(bbox) for bbox in vals[['x_min', 'y_min', 'x_max', 'y_max']].values]} for filename, vals in df_train.groupby('img_id')}}\n",
    "labeled_output_path_train =  os.path.join(base_path, 'output_labeled', f'{raw_ds}_01_labeled', 'train')\n",
    "helper_output_path_train =  os.path.join(base_path, 'output_labeled_extra', f'{raw_ds}_01_labeled_extra', 'train')\n",
    "\n",
    "df_val = pd.read_csv(os.path.join(image_data_path, '_df_val.csv')) #process_df(df[df['val']].copy(), count_per_label=300)\n",
    "bboxes_dict_val = {'bboxes': {f'{filename}.jpg': {vals['label_l2'].values[0]: [np.array(bbox) for bbox in vals[['x_min', 'y_min', 'x_max', 'y_max']].values]} for filename, vals in df_val.groupby('img_id')}}\n",
    "labeled_output_path_val =  os.path.join(base_path, 'output_labeled', f'{raw_ds}_01_labeled', 'val')\n",
    "helper_output_path_val =  os.path.join(base_path, 'output_labeled_extra', f'{raw_ds}_01_labeled_extra', 'val')\n",
    "\n",
    "\n",
    "model_type = 'vit_h'\n",
    "points_per_batch = 16 # change based on available gpu memory and model\n",
    "\n",
    "#raw_ds = 'fishery_simple_v1'\n",
    "#bboxes_dict = {'bboxes': {filename: {vals['class'].values[0]: [np.array(bbox) for bbox in vals[['xmin', 'ymin', 'xmax', 'ymax']].values]} for filename, vals in df.groupby('filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2fddbc-ebe7-466d-b03e-19a61d899b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 16), (2100, 16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d0663",
   "metadata": {},
   "source": [
    "#### install remaining dependencies, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d14078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import supervision, segment_anything\n",
    "    deps_install_needed = False\n",
    "except:\n",
    "    deps_install_needed = True\n",
    "\n",
    "if deps_install_needed:\n",
    "    # sam python package\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "    # other packages\n",
    "    %pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision\n",
    "\n",
    "    import supervision as sv\n",
    "    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "import supervision as sv\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=weights_path).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08e0df",
   "metadata": {},
   "source": [
    "#### Download sam weights, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de214119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_download_needed = not os.path.isfile(weights_path)\n",
    "\n",
    "if weights_download_needed:        \n",
    "    \n",
    "    %mkdir -p {weights_dir_path}\n",
    "    !wget -P {weights_dir_path} 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
    "\n",
    "\n",
    "if not os.path.isfile(weights_path): raise Exception('sam weights were not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd5b60",
   "metadata": {},
   "source": [
    "## bboxes to segments and cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad46b44-59fd-4236-b6c2-14f6bf7000ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e8da0d-5e8f-4059-99cb-ee959409a58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    assert bbox1[0] < bbox1[2]\n",
    "    assert bbox1[1] < bbox1[3]\n",
    "    assert bbox2[0] < bbox2[2]\n",
    "    assert bbox2[1] < bbox2[3]\n",
    "\n",
    "    x_left = max(bbox1[0], bbox2[0])\n",
    "    y_top = max(bbox1[1], bbox2[1])\n",
    "    x_right = min(bbox1[2], bbox2[2])\n",
    "    y_bottom = min(bbox1[3], bbox2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    bbox1_area = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])\n",
    "    bbox2_area = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])\n",
    "\n",
    "    iou = intersection_area / float(bbox1_area + bbox2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f354b6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_widget_box(widget_box):\n",
    "    return np.array([\n",
    "        widget_box['x'], \n",
    "        widget_box['y'], \n",
    "        widget_box['x'] + widget_box['width'], \n",
    "        widget_box['y'] + widget_box['height']\n",
    "    ])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97a2e03b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def best_detection_for_bbox(mask_predictor, image_bgr, image_bbox):\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    mask_predictor.set_image(image_rgb)\n",
    "    masks, scores, logits = mask_predictor.predict(box=image_bbox, multimask_output=True)\n",
    "    detections = sv.Detections(xyxy=sv.mask_to_xyxy(masks=masks), mask=masks)\n",
    "    return detections[detections.area == np.max(detections.area)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89005dca-6293-4476-8a77-340d8164618c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_detection(sam_detections, label_detection):\n",
    "    best_detection, best_iou = None, 0\n",
    "    for sam_detection in sam_detections:\n",
    "        iou_value = iou(label_detection.xyxy[0], sam_detection.xyxy[0])\n",
    "        if iou_value > best_iou:\n",
    "            best_iou = iou_value\n",
    "            best_detection = sam_detection\n",
    "    return best_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccfce407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_detection(image_bgr, detection):\n",
    "    x1,y1,x2,y2 = detection.xyxy[0]\n",
    "    seg_mask = detection.mask[0]\n",
    "    segment_bbox = image_bgr[y1:y2,x1:x2]\n",
    "    segment_cut = np.where(seg_mask[:,:,None], image_bgr, 0)[y1:y2,x1:x2]\n",
    "    return seg_mask, segment_bbox, segment_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "042829c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_detection(image_bgr, detection):\n",
    "    seg_mask, segment_bbox, segment_cut = convert_detection(image_bgr, detection)\n",
    "    source_image = sv.BoxAnnotator(color=sv.Color.red()).annotate(scene=image_bgr.copy(), detections=detection, skip_label=True)\n",
    "    segmented_image =  sv.MaskAnnotator(color=sv.Color.red()).annotate(scene=image_bgr.copy(), detections=detection)\n",
    "    sv.plot_images_grid(\n",
    "        images=[segmented_image, seg_mask, segment_bbox, segment_cut],\n",
    "        grid_size=(2, 2),\n",
    "        titles=['image segmented', 'mask', 'segment bbox', 'segment_cut']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "584db27f-47f2-4101-ba4e-9089c57b4b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xyxy_to_detection(xyxy):\n",
    "    return sv.Detections(xyxy=xyxy[None,:])\n",
    "\n",
    "def sam_result_to_detections(sam_result):\n",
    "    return [sv.Detections(xyxy=sv.mask_to_xyxy(masks=result['segmentation'][None,:,:]), mask=result['segmentation'][None,:]) for result in sam_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bfc9bee-f00e-4e96-bb16-10c4ef863f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO simplify\n",
    "def save_segments(image_bgr, detection, image_name, label, output_path, helper_output_path, segment_nr, label_detection=None):\n",
    "    output_dir = os.path.join(output_path, label)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    seg_mask, segment_bbox, segment_cut = convert_detection(image_bgr, detection)\n",
    "\n",
    "    out_name = f\"{image_name.split('.')[0]}_{segment_nr}\"\n",
    "    cv2.imwrite(os.path.join(output_dir, f'{out_name}_CUT.jpg'), segment_cut)\n",
    "    \n",
    "    if label == 'NONE': return\n",
    "\n",
    "    helper_output_dir = os.path.join(helper_output_path, image_name.split('.')[0], label, str(segment_nr))\n",
    "    os.makedirs(helper_output_dir, exist_ok=True)\n",
    "    \n",
    "    if label_detection: label_bbox_image = sv.BoxAnnotator(color=sv.Color.red()).annotate(scene=image_bgr.copy(), detections=label_detection, skip_label=True)\n",
    "    segmented_image =  sv.MaskAnnotator(color=sv.Color.red()).annotate(scene=image_bgr.copy(), detections=detection)\n",
    "    sam_bbox_image = sv.BoxAnnotator(color=sv.Color.red()).annotate(scene=image_bgr.copy(), detections=detection, skip_label=True)\n",
    "\n",
    "    if label_detection: cv2.imwrite(os.path.join(helper_output_dir, f'{out_name}_LABEL_BBOX.jpg'), label_bbox_image)\n",
    "    cv2.imwrite(os.path.join(helper_output_dir, f'{out_name}_SAM_BBOX.jpg'), sam_bbox_image)\n",
    "    cv2.imwrite(os.path.join(helper_output_dir, f'{out_name}_SEGEMENTED.jpg'), segmented_image)\n",
    "    cv2.imwrite(os.path.join(helper_output_dir, f'{out_name}_MASK.jpg'), seg_mask.astype('uint8') * 255)\n",
    "    cv2.imwrite(os.path.join(helper_output_dir, f'{out_name}_BBOX.jpg'), segment_bbox)\n",
    "    cv2.imwrite(os.path.join(helper_output_dir, f'{out_name}_CUT.jpg'), segment_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adce668-5675-44f0-94a8-b1ef8a4c9d78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SAM methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3e577f-e936-427b-8e8a-06b022c15771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_best_segment_for_labels(mask_predictor, bboxes_dict, image_data_dir, output_dir, extra_output_dir):\n",
    "    for image_name in tqdm(bboxes_dict['bboxes']):\n",
    "        image_bgr = cv2.imread(os.path.join(image_data_dir, image_name))\n",
    "        for label, bboxes in bboxes_dict['bboxes'][image_name].items():\n",
    "            for segment_nr, bbox in enumerate(bboxes):\n",
    "                best_detection = best_detection_for_bbox(mask_predictor, image_bgr, bbox)\n",
    "                save_segments(image_bgr, best_detection, image_name, label, output_dir, extra_output_dir, segment_nr+1, label_detection=xyxy_to_detection(bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10ab7ea-df90-4d9a-9307-6c7c6a005f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_all_segments(mask_generator, image_names, image_data_path, output_dir):\n",
    "    for image_name in tqdm(image_names):\n",
    "        image_bgr = cv2.imread(os.path.join(image_data_path, image_name))\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "       \n",
    "        sam_result = mask_generator.generate(image_rgb)\n",
    "        for segment_nr, detection in enumerate(sam_result_to_detections(sam_result)):\n",
    "            save_segments(image_bgr, detection, image_name, 'NONE', output_dir, '', segment_nr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e28d5dae-2f15-4730-9c42-abd5b49cfde3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_all_segments_exclude_labels(mask_generator, bboxes_dict, image_data_path, output_dir):\n",
    "    for image_name in tqdm(bboxes_dict['bboxes']):\n",
    "        image_bgr = cv2.imread(os.path.join(image_data_path, image_name))\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        sam_result = mask_generator.generate(image_rgb)\n",
    "        sam_detections = sam_result_to_detections(sam_result)\n",
    "        for bboxes in bboxes_dict['bboxes'][image_name].values():\n",
    "            for bbox in bboxes:\n",
    "                best_detection = get_best_detection(sam_detections, xyxy_to_detection(bbox))\n",
    "                if best_detection: sam_detections.remove(best_detection)\n",
    "                \n",
    "        for segment_nr, sam_detection in enumerate(sam_detections):\n",
    "            save_segments(image_bgr, sam_detection, image_name, 'NONE', output_dir, '', segment_nr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "355ec552-de7e-42d5-b9ba-12da42149658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_all_segments_seperate_labels(mask_generator, bboxes_dict, image_data_path, output_dir, helper_output_dir, row_nr=0):\n",
    "    \n",
    "    for image_name in tqdm(bboxes_dict['bboxes']):\n",
    "        image_bgr = cv2.imread(os.path.join(image_data_path, image_name))\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        sam_result = mask_generator.generate(image_rgb)\n",
    "        sam_detections = sam_result_to_detections(sam_result)\n",
    "        segment_nr = 1\n",
    "        for label, bboxes in bboxes_dict['bboxes'][image_name].items():\n",
    "            for bbox in bboxes:\n",
    "                best_detection = get_best_detection(sam_detections, xyxy_to_detection(bbox))\n",
    "                if best_detection:\n",
    "                    sam_detections.remove(best_detection)\n",
    "                    save_segments(image_bgr, best_detection, image_name, label, os.path.join(output_dir, 'NONE', image_name), helper_output_dir, segment_nr)\n",
    "                    segment_nr += 1\n",
    "                \n",
    "        for sam_detection in sam_detections:\n",
    "            save_segments(image_bgr, sam_detection, image_name, 'NONE', os.path.join(output_dir, 'NONE', image_name), '', segment_nr)\n",
    "            segment_nr += 1\n",
    "            \n",
    "        with open('latest_row.txt', 'w') as f:\n",
    "            f.write(str(row_nr))\n",
    "            row_nr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024e1ba-3f5e-4272-83c7-342cca3f416d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Execution \n",
    "### Warning: This might overwrite existing files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9e804-cfce-4564-b192-de8a90a4c9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab9dd3-c4bb-4fee-8f12-51899a5c32bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mask_predictor = SamPredictor(sam)\n",
    "#store_best_segment_for_labels(mask_predictor, bboxes_dict_train, image_data_path, labeled_output_path_train, helper_output_path_train)\n",
    "#store_best_segment_for_labels(mask_predictor, bboxes_dict_val, image_data_path, labeled_output_path_val, helper_output_path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "badae7f8-6f1e-4145-870b-c4cadb6538af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_generator = SamAutomaticMaskGenerator(sam, points_per_batch=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedaab4-09fd-4378-aeed-58ac0e626ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "# row_nr = 0\n",
    "# bboxes_dict_train_row_nr = {'bboxes': {k: v for k, v in list(bboxes_dict_train['bboxes'].items())[row_nr:]}}\n",
    "# len(bboxes_dict_train['bboxes']), len(bboxes_dict_train_row_nr['bboxes'])\n",
    "#store_all_segments_seperate_labels(mask_generator, bboxes_dict_train_row_nr, image_data_path, labeled_output_path_train, os.path.join(helper_output_path_train, '_best_segments'), row_nr=row_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce13788d-0248-43f6-93b2-d334c4f4426e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecff157c5e543c98ec2683741142974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1891 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VAL\n",
    "store_all_segments_seperate_labels(mask_generator, bboxes_dict_val_row_nr, image_data_path, labeled_output_path_val, os.path.join(helper_output_path_val, '_best_segments'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
