{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326033ee-4e7b-4f78-84d7-bacb4ad57f21",
   "metadata": {},
   "source": [
    "# Fuctionality to turn images into segment images and store them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea63ab",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9055712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, torch, math, gc, numpy as np, cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a86be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# paths\n",
    "base_path = os.getcwd() if not IS_COLAB else '/content/drive/MyDrive/ba'\n",
    "weights_dir_path = os.path.join(base_path, 'weights')\n",
    "weights_path = os.path.join(weights_dir_path, 'sam_vit_h_4b8939.pth')\n",
    "data_path =  os.path.join(base_path, 'raw_data', 'mattress_target')\n",
    "output_path =  os.path.join(base_path, 'output_segmented', 'mattress_target')\n",
    "\n",
    "# sam settings\n",
    "model_type = 'vit_h'\n",
    "\n",
    "points_per_batch = 16 # change based on available gpu memory and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddef1bb",
   "metadata": {},
   "source": [
    "## download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7d944f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_download_needed = not os.path.isfile(weights_path)\n",
    "\n",
    "if weights_download_needed:        \n",
    "    \n",
    "    %mkdir -p {weights_dir_path}\n",
    "    !wget -P {weights_dir_path} 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
    "\n",
    "\n",
    "if not os.path.isfile(weights_path): raise Exception('sam weights were not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d1ffc",
   "metadata": {},
   "source": [
    "## install and import remaining dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031fd00d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import supervision, segment_anything\n",
    "    deps_install_needed = False\n",
    "except:\n",
    "    deps_install_needed = True\n",
    "\n",
    "if deps_install_needed:\n",
    "    # sam python package\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "    # other packages\n",
    "    %pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision\n",
    "\n",
    "    import supervision as sv\n",
    "    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "import supervision as sv\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0c467",
   "metadata": {},
   "source": [
    "##  methods to segment images and the segment bboxes and cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c2a7462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_annotated_image(img_path, sam_masks):\n",
    "    return sv.MaskAnnotator().annotate(\n",
    "        scene=cv2.imread(img_path),\n",
    "        detections= sv.Detections.from_sam(sam_result=sam_result)\n",
    "    )\n",
    "\n",
    "def gen_segment_images(img_bgr, sam_mask):\n",
    "    x,y,w,h = [int(x) for x in sam_mask['bbox']]\n",
    "    segment_bbox = img_bgr[y:y+h, x:x+w]\n",
    "    segment_cut = np.where(sam_mask['segmentation'][:,:,None], img_bgr, 0)[y:y+h, x:x+w]\n",
    "    return segment_bbox, segment_cut\n",
    "\n",
    "def store_segments(sam_masks, img_bgr, img_name, output_path, silent=False):\n",
    "    # create directories\n",
    "    output_img_path = os.path.join(output_path, img_name.split('.')[0])\n",
    "    output_img_bbox_path = os.path.join(output_img_path, 'segment_bbox')\n",
    "    output_img_cut_path = os.path.join(output_img_path, 'segment_cuts')\n",
    "    os.makedirs(output_img_bbox_path, exist_ok=True)\n",
    "    os.makedirs(output_img_cut_path, exist_ok=True)\n",
    "    \n",
    "    # save bbox and cut segments\n",
    "    num_digits = int(math.log10(len(sam_masks))) + 1\n",
    "    for i, sam_mask in enumerate(sam_masks if silent else tqdm(sam_masks)):\n",
    "        segment_bbox, segment_cut = gen_segment_images(img_bgr, sam_mask)\n",
    "        cv2.imwrite(os.path.join(output_img_bbox_path, f'bbox_{i:0{num_digits}}.jpg'), segment_bbox)\n",
    "        cv2.imwrite(os.path.join(output_img_cut_path, f'cut_{i:0{num_digits}}.jpg'), segment_cut)\n",
    "\n",
    "def proccess_img(mask_generator, img_dir, img_name, output_path, silent=False):\n",
    "    img_bgr = cv2.imread(os.path.join(img_dir, img_name))\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    sam_masks = mask_generator.generate(img_rgb)\n",
    "    sorted_sam_masks = sorted(sam_masks, key=lambda x: x['predicted_iou'], reverse=True)\n",
    "    store_segments(sorted_sam_masks, img_bgr, img_name, output_path, silent=silent)\n",
    "\n",
    "def proccess_img_dir(img_dir, model_type, weights_path, output_path, points_per_batch):\n",
    "    sam = sam_model_registry[model_type](checkpoint=weights_path).to(device=device)\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam, points_per_batch=points_per_batch)\n",
    "    for img_name in tqdm(os.listdir(img_dir)):\n",
    "        if img_name.startswith('.'): continue\n",
    "        proccess_img(mask_generator, img_dir, img_name, output_path, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acb420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proccess_img_dir(data_path, model_type, weights_path, output_path, points_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d990322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sam = sam_model_registry[model_type](checkpoint=weights_path).to(device=device)\n",
    "#mask_generator = SamAutomaticMaskGenerator(sam, points_per_batch=points_per_batch)\n",
    "#proccess_img(mask_generator, data_path, 'mattress1.jpg', output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
